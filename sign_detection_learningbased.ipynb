{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4bb637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2021  IBM Corporation\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb7515-641d-48f9-b3a0-c96dc54ce424",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "from sign_dataset import SignDataset\n",
    "import modules.datautils as datautils\n",
    "from modules.models import GraphAttentionNet\n",
    "from modules import losses\n",
    "from modules.training import train_graph_attention_net\n",
    "from modules import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import visualization as vis\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f91de-97b9-40aa-b01e-3607afc22356",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f7682-3f3f-45a5-b922-c96e5e3db793",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'dataset/processed_data/'\n",
    "dict_categories = np.load(os.path.join(data_folder, 'categories.npy'), allow_pickle=True).item()\n",
    "n_categories = len(dict_categories['cat_relabel'])\n",
    "\n",
    "# create SignDataset object\n",
    "sign_dataset = SignDataset(data_folder, n_categories, 'train', max_data=370, augment_crop=True)\n",
    "test_dataset = SignDataset(data_folder, n_categories, 'test', augment_crop=False)\n",
    "\n",
    "# dataloader\n",
    "sign_dataloader = datautils.GroupDataLoader(sign_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de31c85-8861-4dc9-b533-ef80011e3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b18e5a-2742-4afc-8b9c-8a20af673fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignFeatExtractor(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_input):\n",
    "        super(SignFeatExtractor, self).__init__()\n",
    "        \n",
    "        self.dim_input = dim_input\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(7, 64, [5, 5], stride=2, padding=2)\n",
    "        self.norm1 = nn.GroupNorm(4, 64)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, [5, 5], stride=2, padding=2)\n",
    "        self.norm2 = nn.GroupNorm(4, 128)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 128, [5, 5], stride=2, padding=2)\n",
    "        self.norm3 = nn.GroupNorm(4, 128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 128, [5, 5], stride=2, padding=2)\n",
    "        self.norm4 = nn.GroupNorm(4, 128)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(128, 64, [16, 16], stride=2)\n",
    "        self.norm5 = nn.GroupNorm(4, 64)\n",
    "        \n",
    "        self.leaky_relu_p = 0.2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = F.leaky_relu(x, self.leaky_relu_p)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = F.leaky_relu(x, self.leaky_relu_p)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = F.leaky_relu(x, self.leaky_relu_p)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.norm4(x)\n",
    "        x = F.leaky_relu(x, self.leaky_relu_p)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).squeeze()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "node_feature_extractor = SignFeatExtractor(7) # here, 7 is 3 color channels + 4 possible sign categories\n",
    "with torch.no_grad():\n",
    "    print(node_feature_extractor(torch.randn(5,7,313,256)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad27999f-6a4b-4309-aed6-29fee3607eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = GraphAttentionNet(2, \n",
    "                          dim_node_input=64, \n",
    "                          dim_edge_input=64,\n",
    "                          dim_edge_output=1, \n",
    "                          n_heads=4, \n",
    "                          use_residual=True, \n",
    "                          use_norm=True, \n",
    "                          node_feature_extractor=node_feature_extractor)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbedd60-af5b-4a31-8c7d-73580b273784",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "# scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9043c6b-1360-4955-a1b5-18c660ec237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_group_affinity = losses.SemisupervisedGroupClusteringLoss(['output_edge', 'gt_aff_mat', 'list_idx_label_group'], balance=True, fl_gamma=2)\n",
    "\n",
    "# combine the loss into LossCollection object\n",
    "loss_collection = losses.LossCollection()\n",
    "loss_collection.add_loss(\"clustering\", losses_group_affinity, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0c8ec-50a0-4db8-923f-177824989830",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'run_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f60bff0-17d6-4909-8a42-f86d01147630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "freq_save_model = 10\n",
    "it_model = 0\n",
    "\n",
    "train_graph_attention_net(\n",
    "        model, \n",
    "        sign_dataloader,\n",
    "        loss_collection,\n",
    "        optimizer,\n",
    "        n_epochs,\n",
    "        'tb_synth_{}/{:04d}/'.format(run_name, it_model),\n",
    "        'model_save_{}/{:04d}/'.format(run_name, it_model),\n",
    "        freq_save_model,\n",
    "        device,\n",
    "#         scheduler=scheduler\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16127dd6-a5f7-41de-827f-32f626a1ab02",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47350b33-6820-4f3d-a463-06c818eac6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # pick an image to test\n",
    "    sample = test_dataset[388]\n",
    "    output_node, output_edge = model(None, sample=sample)\n",
    "    oe_s = torch.sigmoid(output_edge)\n",
    "    oe_s = (oe_s+oe_s.T)/2\n",
    "    \n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(oe_s.detach().cpu().numpy(), vmin=0, vmax=1)\n",
    "axs[1].imshow(oe_s.detach().cpu().numpy() > 0.5, vmin=0, vmax=1)\n",
    "axs[2].imshow(sample.gt_aff_mat, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d908e-9ed6-4b7f-b4f4-5ccdd93c4841",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_clustering = model.infer_clusters(None, sample=sample)\n",
    "output_block_labels = output_clustering['group_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb70f8e-1b7c-4a27-9f83-1dd0af544dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fileloc = os.path.join('dataset/raw/images/',sample.details['filename'])\n",
    "print(image_fileloc)\n",
    "img_bgr = cv2.imread(image_fileloc)\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "bboxes = sample.details['segm']\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(15, 15))\n",
    "# vis.visualize_groups(axs, np.repeat(im_bw[:,:,None], 3, axis=2) , bboxes, output_block_labels, None)\n",
    "img_rgb_tmp = (sample.node_feature[0][:3].permute([1,2,0]).detach().cpu().numpy())/2+0.5\n",
    "vis.visualize_groups(axs, img_rgb_tmp, bboxes, output_block_labels, None)\n",
    "axs.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8653cab5-11be-41f0-a2ec-482444f4cc73",
   "metadata": {},
   "source": [
    "# Run test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae73c6-7494-43d4-bd55-1f35251dac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_data_test = np.arange(370, 412)\n",
    "\n",
    "# dict for saving data\n",
    "dict_clus_acc = {}\n",
    "\n",
    "# loop thru test data\n",
    "for it_data in tqdm(idx_data_test):\n",
    "    with torch.no_grad():\n",
    "        sample = test_dataset[it_data]\n",
    "        output_clustering = model.infer_clusters(None, sample=sample)\n",
    "        output_block_labels = output_clustering['group_id']\n",
    "        \n",
    "    clus_acc_it = metrics.compute_cluster_accuracy(sample.node_group_id, output_block_labels)\n",
    "    dict_clus_acc[it_data] = clus_acc_it\n",
    "    \n",
    "avg_clus_acc = np.mean(list(dict_clus_acc.values()))\n",
    "print(\"Average clustering acc: {:.4f}\".format(avg_clus_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
